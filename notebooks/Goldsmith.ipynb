{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goldsmith\n",
    "\n",
    " - Loads the Goldsmith file (MSS12) and exports peaksets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,glob\n",
    "sys.path.append('/home/simon/git/burns/code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/simon/Dropbox/BioResearch/Meta_clustering/Burns/simon_test/'\n",
    "blank_mz_tol = 5\n",
    "mz_tol = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group1 = ['MSS12']\n",
    "files1 = []\n",
    "for g in group1:\n",
    "    pattern = data_dir + g + 'a' + '*.mzML'\n",
    "    matches = glob.glob(pattern)\n",
    "    for match in matches:\n",
    "        end_bit = match.split('/')[-1]\n",
    "        bfile = end_bit.split('a')\n",
    "        bfilename =  \"\".join(bfile[:-1]) + 'b' + bfile[-1]\n",
    "        files1.append((match,data_dir+bfilename))\n",
    "group1,paper1 = zip(*files1)\n",
    "group1 = paper1\n",
    "\n",
    "blank_patterns = 'Blank_*'\n",
    "blank_files = glob.glob(data_dir + blank_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_di import load_di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "for f in files1:\n",
    "    out_file = '../csv_files/' + f[0].split('/')[-1].split('.')[0]+'.csv'\n",
    "    data[f[0]] = load_di(f[0],out_file = out_file,normalise = None,mz_tol = blank_mz_tol)\n",
    "    data[f[1]] = load_di(f[1],out_file = out_file,normalise = None,mz_tol = blank_mz_tol)\n",
    "    \n",
    "for b in blank_files:\n",
    "    out_file = '../csv_files/' + b.split('/')[-1].split('.')[0]+'.csv'\n",
    "    data[b] = load_di(b,out_file = out_file,normalise = None,mz_tol = blank_mz_tol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7235 peaks\n"
     ]
    }
   ],
   "source": [
    "from matching import Greedy\n",
    "import csv\n",
    "import numpy as np\n",
    "options = {'log':'log','normalise':'tus','missing':1e-5}\n",
    "if options['normalise'] == 'tus':\n",
    "    normalised_data = {}\n",
    "    for f,spec in data.items():\n",
    "        mz_list,i_list = zip(*spec)\n",
    "        tot_intensity = sum(i_list)\n",
    "        new_intensity = [1000.0*i/tot_intensity for i in i_list]\n",
    "        new_spec = zip(mz_list,new_intensity)\n",
    "        normalised_data[f] = new_spec\n",
    "elif options['normalise'] == 'none':\n",
    "    normalised_data = data\n",
    "    \n",
    "g = Greedy()\n",
    "mp = g.process(normalised_data,mz_tol)\n",
    "\n",
    "display_names = {}\n",
    "for g in group1:\n",
    "    display_names[g] = g.split('/')[-1]\n",
    "\n",
    "all_names = list(group1)\n",
    "res = []\n",
    "\n",
    "\n",
    "heads = [\"mz\"] + [display_names[a] for a in all_names] + [\"n_blank\"]\n",
    "for ps in mp:\n",
    "    row = [ps.mean_mz]\n",
    "    g1 = []\n",
    "    for n in all_names:\n",
    "        peak = filter(lambda x: x[2] == n,ps.peaks)\n",
    "        if len(peak) == 0:\n",
    "            row.append(\"nan\")\n",
    "            # take max intensity\n",
    "            peak = sorted(peak,key = lambda x: x[1], reverse = True)\n",
    "        else:\n",
    "            row.append(peak[0][1])\n",
    "        if n in group1:\n",
    "            g1.append(row[-1])\n",
    "\n",
    "    ng1 = sum([1 for a in g1 if not a == \"nan\"])\n",
    "    if options['missing'] == 'nan':\n",
    "        g1 = [a for a in g1 if not a == \"nan\"]\n",
    "    else:\n",
    "        g1 = [a if not a == \"nan\" else options[\"missing\"] for a in g1]\n",
    "    if options['log'] == 'log':\n",
    "        g1 = [np.log10(a) for a in g1]\n",
    "\n",
    "\n",
    "    b_count = 0\n",
    "    for n in blank_files:\n",
    "        peak = filter(lambda x: x[2] == n,ps.peaks)\n",
    "        if len(peak) > 0:\n",
    "            b_count += 1\n",
    "            \n",
    "    row.append(b_count)\n",
    "    res.append(row)\n",
    "\n",
    "# Sort by number present\n",
    "res = sorted(res,key = lambda x: sum([1 if l == 'nan' else 0 for l in x]))\n",
    "# remove those only present in the blanks\n",
    "res = filter(lambda x: sum([1 if l == 'nan' else 0 for l in x])<4,res)\n",
    "    \n",
    "with open(\"spreadsheets/goldsmith/goldsmith_{}_{}_{}.csv\".format(options['log'],options['missing'],options['normalise']),'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(heads)\n",
    "    for r in res:\n",
    "        writer.writerow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
